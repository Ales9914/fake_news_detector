{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detector - Model comparison\n",
    "\n",
    "## Authors\n",
    "- Jose Garzon\n",
    "- Germán Patiño\n",
    "- Alejandro Salazar\n",
    "\n",
    "*Universidad EAFIT*\n",
    "## References\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb\n",
    "* https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb\n",
    "* https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Spark NLP version 5.3.3\n",
      "Apache Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import sparknlp\n",
    "\n",
    "ss = sparknlp.start() \n",
    "sparknlp.start(gpu=True) # >> for training on GPU\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", ss.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion for conver Pandas Dataframe to Spark Dataframe\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType\n",
    "def read_data(path):\n",
    "  schema= StructType(\n",
    "      [StructField('title',StringType(),True),\n",
    "      StructField('text',StringType(),True),\n",
    "      StructField('label',IntegerType(),True)])\n",
    "  pd_df= pd.read_csv(path).drop('Unnamed: 0', axis= 1)\n",
    "  sp_df= ss.createDataFrame(pd_df, schema= schema)\n",
    "  return sp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data set\n",
    "path_data= 'WELFake_Dataset.csv'\n",
    "data= read_data(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, coalesce, lit, when, col, isnan\n",
    "\n",
    "# Define the transformation logic to create the full_text column\n",
    "data = data.withColumn(\n",
    "    \"full_text\",\n",
    "    concat(\n",
    "        coalesce(when(col(\"title\").isNotNull() & ~isnan(col(\"title\")), col(\"title\")).otherwise(lit(\"\")), lit(\"\")),\n",
    "        lit(\" \"),\n",
    "        coalesce(when(col(\"text\").isNotNull() & ~isnan(col(\"text\")), col(\"text\")).otherwise(lit(\"\")), lit(\"\"))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+\n",
      "|               title|                text|label|           full_text|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|LAW ENFORCEMENT O...|No comment is exp...|    1|LAW ENFORCEMENT O...|\n",
      "|                 NaN|Did they post the...|    1| Did they post th...|\n",
      "|UNBELIEVABLE! OBA...| Now, most of the...|    1|UNBELIEVABLE! OBA...|\n",
      "|Bobby Jindal, rai...|A dozen political...|    0|Bobby Jindal, rai...|\n",
      "|SATAN 2: Russia u...|The RS-28 Sarmat ...|    1|SATAN 2: Russia u...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset, testDataset= data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_bert_L4_256 download started this may take some time.\n",
      "Approximate size to download 40,5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"full_text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "bert_embeddings = BertEmbeddings().pretrained(name='bert_base_uncased', lang='en') \\\n",
    "    .setInputCols([\"document\",'token'])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"class\")\\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setMaxEpochs(10)\\\n",
    "    .setLr(0.001)\\\n",
    "    .setBatchSize(8)\\\n",
    "    .setEnableOutputLogs(True) \\\n",
    "    .setOutputLogsPath('logs')\n",
    "\n",
    "bert_clf_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        bert_embeddings,\n",
    "        embeddingsSentence,\n",
    "        classsifierdl\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 14min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bert_clf_pipelineModel = bert_clf_pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bert_clf_pipelineModel.transform(testDataset)\n",
    "preds_df = preds.select('label','full_text',\"class.result\").toPandas()\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      7011\n",
      "           1       0.93      0.94      0.93      7285\n",
      "\n",
      "    accuracy                           0.93     14296\n",
      "   macro avg       0.93      0.93      0.93     14296\n",
      "weighted avg       0.93      0.93      0.93     14296\n",
      "\n",
      "0.9327783995523223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(classification_report(preds_df.label, preds_df.result))\n",
    "print(accuracy_score(preds_df.label, preds_df.result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72134"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "      .setInputCol(\"full_text\") \\\n",
    "      .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "      .setInputCols([\"token\"]) \\\n",
    "      .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "      .setInputCols([\"cleanTokens\"]) \\\n",
    "      .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "      .setInputCols([\"stem\"]) \\\n",
    "      .setOutputCols([\"token_features\"]) \\\n",
    "      .setOutputAsArray(True) \\\n",
    "      .setCleanAnnotations(False)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=20) #minDocFreq: remove sparse terms\n",
    "\n",
    "nlp_pipeline_tf = Pipeline(\n",
    "    stages=[document_assembler,\n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner,\n",
    "            stemmer,\n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf])\n",
    "\n",
    "nlp_model_tf = nlp_pipeline_tf.fit(data)\n",
    "\n",
    "processed_tf = nlp_model_tf.transform(data)\n",
    "\n",
    "processed_tf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|           full_text|            features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|LAW ENFORCEMENT O...|(10000,[29,71,88,...|    1|\n",
      "| Did they post th...|(10000,[568,2460,...|    1|\n",
      "|UNBELIEVABLE! OBA...|(10000,[639,1226,...|    1|\n",
      "|Bobby Jindal, rai...|(10000,[15,24,39,...|    0|\n",
      "|SATAN 2: Russia u...|(10000,[33,58,63,...|    1|\n",
      "|About Time! Chris...|(10000,[171,387,5...|    1|\n",
      "|DR BEN CARSON TAR...|(10000,[281,472,1...|    1|\n",
      "|HOUSE INTEL CHAIR...|(10000,[472,681,7...|    1|\n",
      "|Sports Bar Owner ...|(10000,[24,35,88,...|    1|\n",
      "|Latest Pipeline L...|(10000,[104,116,1...|    1|\n",
      "| GOP Senator Just...|(10000,[35,58,150...|    1|\n",
      "|May Brexit offer ...|(10000,[8,23,29,1...|    0|\n",
      "|Schumer calls on ...|(10000,[15,51,52,...|    0|\n",
      "|WATCH: HILARIOUS ...|(10000,[493,568,7...|    1|\n",
      "|No Change Expecte...|(10000,[4,29,151,...|    0|\n",
      "|Billionaire Odebr...|(10000,[63,158,25...|    0|\n",
      "|BRITISH WOMAN LOS...|(10000,[15,57,158...|    1|\n",
      "|U.N. seeks humani...|(10000,[70,171,30...|    0|\n",
      "|MAJOR LIBERAL RAG...|(10000,[2,15,19,4...|    1|\n",
      "|Second judge says...|(10000,[23,51,171...|    0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_tf.select('full_text','features','label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 50341\n",
      "Test Dataset Count: 21793\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "%%time\n",
    "(trainingData, testData) = processed_tf.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "lrModel_tf = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Islamic State Claims Respon...|[0.9999999999984583,1.54165...|    0|       0.0|\n",
      "|Trump vs. Congress: Now Wha...|[0.9999999986995154,1.30048...|    0|       0.0|\n",
      "|The New Party of No - The N...|[0.9999999918232719,8.17672...|    0|       0.0|\n",
      "|John Kerry: ISIS responsibl...|[0.9999980459449654,1.95405...|    0|       0.0|\n",
      "|Donald Trump’s New York Tim...|[0.999992285404873,7.714595...|    0|       0.0|\n",
      "|When to Leave on Your Thank...|[0.9999717399375468,2.82600...|    0|       0.0|\n",
      "|Taxpayers Will Defend Trump...|[0.9999215405252954,7.84594...|    0|       0.0|\n",
      "|Tragedy Made Steve Kerr See...|[0.9999176697149388,8.23302...|    0|       0.0|\n",
      "|President Obama's final Sta...|[0.9998598929562378,1.40107...|    0|       0.0|\n",
      "|Factbox: International reac...|[0.9998565361943241,1.43463...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_tf = lrModel_tf.transform(testData)\n",
    "predictions_tf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     10554\n",
      "           1       0.93      0.96      0.95     11239\n",
      "\n",
      "    accuracy                           0.94     21793\n",
      "   macro avg       0.94      0.94      0.94     21793\n",
      "weighted avg       0.94      0.94      0.94     21793\n",
      "\n",
      "0.9426421327949341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_true = predictions_tf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_tf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------------------+-----+----------+\n",
      "|                     full_text|                   probability|label|prediction|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "|Trump says he will back awa...|[0.6798491053129065,0.32015...|    0|       0.0|\n",
      "|Biden visits Iraq in show o...|[0.6693317038369164,0.33066...|    0|       0.0|\n",
      "|Trump warns 'rogue regime' ...|[0.6678553529713492,0.33214...|    0|       0.0|\n",
      "|South Korea braces for poss...|[0.6669086312656742,0.33309...|    0|       0.0|\n",
      "|Trump says U.S. committed t...|[0.6664639064909074,0.33353...|    0|       0.0|\n",
      "|Trump to press China on Nor...|[0.6660941432660828,0.33390...|    0|       0.0|\n",
      "|Republican disarray deepens...|[0.6655025403157779,0.33449...|    0|       0.0|\n",
      "|Puerto Rico debt bill gains...|[0.6654954059595326,0.33450...|    0|       0.0|\n",
      "|Trump hails deals worth 'bi...|[0.6653982157702998,0.33460...|    0|       0.0|\n",
      "|Trump warns 'rogue regime' ...|[0.6644860229273957,0.33551...|    0|       0.0|\n",
      "+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = rfModel.transform(testData)\n",
    "predictions_rf.select(\"full_text\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84     10554\n",
      "           1       0.83      0.91      0.87     11239\n",
      "\n",
      "    accuracy                           0.86     21793\n",
      "   macro avg       0.86      0.86      0.86     21793\n",
      "weighted avg       0.86      0.86      0.86     21793\n",
      "\n",
      "0.8568806497499197\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions_rf.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = predictions_rf.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "print(classification_report(y_true.label, y_pred.prediction))\n",
    "print(accuracy_score(y_true.label, y_pred.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel.save('rfModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
